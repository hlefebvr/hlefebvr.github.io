# MKP

```{r, echo = FALSE, warning = FALSE, message = FALSE}
library(ggplot2)
library(rmarkdown)
suppressWarnings(library(dplyr))
library(knitr)
library(kableExtra)
library(stringr)
library(RColorBrewer)
library(tidyr)
```

## Some helper functions first

```{r}
make_heatmap = function(data) {
  
  max_count = data %>%
    count(n_items, n_knapsacks) %>%
    pull(n) %>%
    max()
  
  # Step 1: Get all existing combinations in the original data
  existing_combinations = data %>% distinct(n_items, n_knapsacks)
  
  # Step 2: Get all combinations of existing values
  full_grid = expand_grid(
    n_items = unique(data$n_items),
    n_knapsacks = unique(data$n_knapsacks)
  )
  
  # Step 3: Mark whether the pair exists in the original data
  full_grid = full_grid %>%
    left_join(existing_combinations %>% mutate(exists = TRUE), by = c("n_items", "n_knapsacks"))
  
  # Step 4: Count how many rows are below the time limit
  counts = data %>%
    filter(total_time < 10800) %>%
    count(n_items, n_knapsacks, name = "count")
  
  # Step 5: Join the count info into the full grid
  summary_data = full_grid %>%
    left_join(counts, by = c("n_items", "n_knapsacks"))
  
  # Step 6: Set count = 0 where pair exists but no row meets time condition
  summary_data = summary_data %>%
    mutate(
      count = ifelse(is.na(count) & exists == TRUE, 0, count)
    )
  
  # Step 7: Plot with text
  p = ggplot(summary_data, aes(x = factor(n_items), y = factor(n_knapsacks), fill = count)) +
    geom_tile(color = "white") +
    geom_text(aes(label = ifelse(!is.na(count), count, "")), color = "black") +
    scale_fill_gradient(
      low = "white", high = "darkgreen", na.value = "black",
      limits = c(0,max_count)
    ) +
    labs(
      title = "Number of solved instances within the time limit",
      x = "Number of Facilities",
      y = "Number of Customers",
      fill = "Count"
    ) +
    theme_minimal()
  
  return(p)
}

```

```{r}
make_ecdf_total_time = function(data) {
  p = ggplot(data, aes(x = total_time, color = factor(Gamma), linetype = full_approach ) ) +
      stat_ecdf(geom = "step", linewidth = .5) +
      scale_y_continuous(labels = scales::percent) +
      labs(
        title = "ECDF of Total Computation Time",
        x = "Time (s)",
        y = "Instances (%)",
        color = "Uncertainty budget",
        linetype = "Solution Approach"
      ) +
      theme_minimal() +
      scale_color_brewer(palette = "Set1")
  
  return(p)
}

make_ecdf_gap = function(data) {
  
  p = ggplot(data,
         aes(x = (best_obj - best_bound) / (abs(best_obj) + 1e-10), color = factor(Gamma), linetype = full_approach ) ) +
      stat_ecdf(geom = "step", linewidth = .5) +
      scale_x_continuous(labels = scales::percent) +
      labs(
        title = "ECDF of relative gap with optimality separation",
        x = "Gap (%)",
        y = "Instances (%)",
        color = "Uncertainty budget",
        linetype = "Solution Approach"
      ) +
      theme_minimal() +
      scale_color_brewer(palette = "Set1")
  
  return (p)
}

make_ecdf_master_time = function(data) {
  
  p = ggplot(data,
         aes(x = master_time / total_time, color = factor(Gamma), linetype =  full_approach) ) +
      stat_ecdf(geom = "step", linewidth = .5) +
      scale_x_continuous(labels = scales::percent) +
      scale_y_continuous(labels = scales::percent) +
      labs(
        title = "ECDF of master time / separation time",
        x = "Master time /  Total time (%)",
        y = "Instances (%)",
        color = "Uncertainty budget",
        linetype = "Solution Approach"
      ) +
      theme_minimal() +
      scale_color_brewer(palette = "Set1")
    
  return (p)
}

make_master_time_barplot = function(data) {
  
  # Compute percentages
  plot_data <- data %>%
    dplyr::mutate(
      master_pct = master_time / total_time,
      other_pct  = 1 - master_pct
    ) %>%
    tidyr::pivot_longer(
      cols = c(master_pct, other_pct),
      names_to = "component",
      values_to = "percentage"
    )
  
  # Bar plot
  p <- ggplot(plot_data,
              aes(x = factor(Gamma), y = percentage, fill = component)) +
    geom_bar(stat = "summary", fun = mean, position = "stack") +
    scale_y_continuous(labels = scales::percent) +
    scale_fill_manual(
      values = c(master_pct = "#E41A1C", other_pct = "#377EB8"),
      labels = c("Solving the Master Problem", "Solving the Separation Problem"),
      name = "Time Component"
    ) +
    facet_wrap(~ full_approach) +
    labs(
      title = "Average percentage of time spent on master vs separation",
      x = "Uncertainty budget (Gamma)",
      y = "Average Time (%)"
    ) +
    theme_minimal()
  
  return(p)
}

```

## Robust bilevel problem with wait-and-see follower

```{r}
all_results_wait_and_see = read.csv("results.csv", header = FALSE)
colnames(all_results_wait_and_see) = c("tag",
                          "instance",
                          "n_items",
                          "n_knapsacks", 
                          "Gamma",
                          "blank",
                          "status",
                          "reason",
                          "best_bound",
                          "best_obj",
                          "total_time",
                          "master_time",
                          "separation_time",
                          "n_iterations")

all_results_wait_and_see = all_results_wait_and_see %>%
  mutate(
    master_method = "MibS",
    separation_type = "MibS",
    separation_approach = "MibS",
    full_approach = paste0(master_method, " / ", separation_approach),
    total_time = pmin(total_time, 10800),
    gap = (best_obj - best_bound) / (abs(best_obj) + 1e-10)
  )

all_results_wait_and_see = all_results_wait_and_see %>% filter(n_items <= 15)

all_results_wait_and_see$tag = NULL
all_results_wait_and_see$blank = NULL

paged_table(all_results_wait_and_see)
```

### How Does the Algorithm Perform?

```{r}
make_ecdf_total_time(all_results_wait_and_see)
make_ecdf_gap(all_results_wait_and_see)
make_ecdf_master_time(all_results_wait_and_see)
make_master_time_barplot(all_results_wait_and_see)


write_ecdf_csv = function(data, column_name, filename) {
  
  x_points <- seq(0, max(data[[column_name]]), length.out = 100)

  combinations <- data %>%
    select(full_approach, Gamma) %>%
    distinct()
  
  # Compute ECDF values for each combination
  ecdf_table <- combinations %>%
    rowwise() %>%
    do({
      approach <- .$full_approach
      gamma <- .$Gamma
      
      # Subset the data
      df_sub <- data %>%
        filter(full_approach == approach, Gamma == gamma)
      
      # Compute ECDF
      F <- ecdf(df_sub[[column_name]])
      
      # Evaluate at x_points
      data.frame(
        x = x_points,
        value = F(x_points),
        full_approach = approach,
        Gamma = gamma
      )
    }) %>%
    ungroup()
  
  ecdf_wide <- ecdf_table %>%
    unite("approach_Gamma", full_approach, Gamma, sep = "_") %>%
    pivot_wider(names_from = approach_Gamma, values_from = value)
  
  
  ecdf_wide
  
  write.csv(ecdf_wide, filename, row.names = FALSE, quote = FALSE)
}

write_ecdf_csv(all_results_wait_and_see, "total_time", "mkp-ecdf-time.csv")
write_ecdf_csv(all_results_wait_and_see, "gap", "mkp-ecdf-gap.csv")
```

## What Can We Solve? 

```{r}
wait_and_see_big_M = all_results_wait_and_see %>% filter(full_approach == "MibS / MibS")
make_heatmap(wait_and_see_big_M)
```

## How Many Iterations?

```{r}

wait_and_see_big_M_solved = wait_and_see_big_M %>% filter(total_time < 10800)

avg_iter_wait_and_see <- wait_and_see_big_M_solved %>%
  group_by(n_items, n_knapsacks) %>%
  summarise(avg_iterations = mean(n_iterations, na.rm = TRUE), .groups = "drop") %>%
  mutate(problem_type = "Wait-and-see")

# Step 3: Create a label for each pair to use on the x-axis
avg_iterations_combined <- avg_iter_wait_and_see %>%
  mutate(pair = paste0("(", n_items, ", ", n_knapsacks, ")"))

# Step 4: Plot side-by-side bars
ggplot(avg_iterations_combined, aes(x = pair, y = avg_iterations, fill = problem_type)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
  labs(
    title = "Average number of iterations per instance size",
    x = "Instance size",
    y = "Average number of iterations",
    fill = "Problem type"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


## Summary Table

```{r}
summary_table <- all_results_wait_and_see %>%
  filter(total_time < 10800) %>%
  group_by(full_approach, Gamma, n_items, n_knapsacks) %>%
  summarise(
    #instance = paste(unique(instance), collapse = ", "),
    n_instances = n(),
    avg_total_time = mean(total_time, na.rm = TRUE),
    avg_master_share = mean(master_time / total_time * 100, na.rm = TRUE),
    avg_n_iterations = mean(n_iterations, na.rm = TRUE),
    .groups = "drop"
  )

kable(summary_table)
```
