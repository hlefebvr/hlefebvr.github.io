# "Computing Counterfactual Explanations for Linear Optimization: A New Class of Bilevel Models and a Tailored Penalty Alternating Direction Method > NETLIB"

```{r, echo = FALSE}
library(ggplot2)
library(rmarkdown)
suppressMessages(library(dplyr))
suppressMessages(library(knitr))
suppressMessages(library(kableExtra))
library(tikzDevice)
```

## Loading Results

### Instance Statistics

```{r}
instances = read.csv("instances.csv", header = FALSE)
colnames(instances) = c("tag", "instance", "mps", "n_vars", "n_ctrs")

# Remove tag
instances$tag = NULL

# Clean instance name
instances$instance = sub("_.*", "", basename(instances$instance))
instances$mps = basename(instances$mps)

instances = instances[!duplicated(instances$instance), ]

paged_table(instances)
```

### Results

```{r}

time_limit = 1800

data = rbind(
  read.csv("new-results.csv", header = FALSE)
)
stats = c("time", "status", "reason", "objective", "n_outer_iterations", "n_inner_iterations","l1_norm", "l2_norm")
colnames(data) = c("tag", "instance", "n_vars", "n_ctrs", "desired_space_dim", "n_mutable_coefficients", "n_mutable_costs", "n_mutable_rhs", "method", "update_rule", "update_rule_parameter", "norm", "initial_penalty",  "warm_start", "only_constraints", "sol_file", paste0("warm_start_", stats), stats, "solution_ok", "unconstrained_obj", "constrained_obj", "gap")

data$warm_start_status = ifelse(is.na(data$warm_start_status), "-", data$warm_start_status)

# Remove tag
data$tag = data$n_vars = data$n_ctrs = NULL

# Add a one-word solver description
data$solver = ifelse(data$method == "PADM", paste0(data$method, " - ", data$update_rule, " ", data$update_rule_parameter, " - ", data$norm, " - init ", data$initial_penalty, " - warm start ", data$warm_start, " - only constraints ", data$only_constraints), data$method)

# Add 'n_mutable_columns' based on instance name
data$n_mutable_columns = gsub(".*_(\\d+)$", "\\1", data$instance)

# Clean instance name
data$full_instance = basename(data$instance)

data$instance = sub("_.*", "", data$full_instance)

data$adjusted_time = ifelse(is.na(data$warm_start_time), 0, data$warm_start_time) + data$time
data = data %>% mutate(adjusted_time = ifelse(solution_ok == 0, time_limit, adjusted_time))
data$total_time = data$adjusted_time

data$solved = (data$status == "Optimal" | data$status == "Feasible") & data$adjusted_time < time_limit

n_unsolved = sum(!data$solved)
if (n_unsolved > 0) {
  data[!data$solved,]$adjusted_time = time_limit
}

data$n_mutable_columns <- as.numeric(as.character(data$n_mutable_columns))  # Convert to numeric

```

### Merge Instances and Results

```{r}
data = merge(data, instances[, c("instance", "n_vars", "n_ctrs")], 
                     by = "instance",
                     all.x = TRUE)
```

```{r, echo = FALSE}
paged_table(data)
```

```{r}
data %>% filter(solution_ok == 0, method == "NLP-first", n_mutable_costs == 0) %>% select(instance, full_instance, n_mutable_coefficients, solution_ok, constrained_obj, unconstrained_obj, gap)
```

## Performance Analysis

### Summary Ã  la Kurtz 

This is the same table as Table 6 in "Counterfactual Explanations for Linear Optimization", J. Kurtz (2024). 

We focus on l1-norm with warm-start.

```{r}
padm_with_warm_start = data %>%
  filter(method == "PADM",
         update_rule == "adapt",
         norm == "l1",
         initial_penalty == 5e2,
         warm_start == 1)

var_bounds <- list(c(0, 534), c(534, 2167), c(2167, 22275))
ctr_bounds <- list(c(0, 351), c(351, 906), c(906, 16675))
labels <- c("small", "medium", "large")

summary_table = NULL

for (i in seq_along(labels)) {
  for (j in seq_along(labels)) {
    
    sub_summary_table <- padm_with_warm_start %>%
      filter(
        n_vars >= var_bounds[[i]][1] & n_vars <= var_bounds[[i]][2],
        n_ctrs >= ctr_bounds[[j]][1] & n_ctrs <= ctr_bounds[[j]][2]
      ) %>%
      mutate(
        var_cat = labels[i],
        ctr_cat = labels[j]
      ) %>%
      group_by(var_cat, ctr_cat, n_mutable_columns) %>%
      summarise(
        `# inst.` = n_distinct(instance),  # Count number of instances
        `# full inst.` = n_distinct(full_instance), 
        `feasible (in %)` = sum(solved) / n_distinct(full_instance) * 100,  # Percentage of feasible instances
        `# mutable objective param.` = mean(n_mutable_costs, na.rm = TRUE),  # Avg mutable objective parameters
        `# mutable constraint param.` = mean(n_mutable_coefficients, na.rm = TRUE),  # Avg mutable constraint parameters
        .groups = "drop"
      ) %>%
      arrange(var_cat, ctr_cat, n_mutable_columns) %>%  # Sort by var_cat, ctr_cat, and n_mutable_columns
      ungroup()
    
    summary_table = rbind(summary_table, sub_summary_table)    
    
  }
}

summary_table %>%
  kable("html", align = "c", col.names = c()) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE, position = "center") %>%
  add_header_above(c("n" = 1, "m" = 1, "# mut. columns" = 1, "# inst." = 1, "# full inst." = 1, "feasible (in %)" = 1, 
                     "# mutable objective param." = 1, "# mutable constraint param." = 1)) %>%
  group_rows("small", 1, 6) %>%
  group_rows("medium", 7, 15) %>%
  group_rows("large", 16, 24)

```

### Solved Instances by Number of Mutable Columns

```{r, fig.height = 30, fig.width = 10, eval = FALSE}
bar_data = padm_with_warm_start %>%
  filter(solved == TRUE) %>%  # Only consider solved instances
  group_by(instance, n_mutable_columns) %>%
  summarise(solved_count = n(), .groups = "drop")  # Count solved instances

# Create bar plot
ggplot(bar_data, aes(x = instance, y = solved_count, fill = factor(n_mutable_columns))) +
  geom_bar(stat = "identity", position = "dodge") +  # Bar plot with bars side-by-side
  coord_flip() +
  labs(
    title = "Number of Solved Instances by n_mutable_columns for Each Instance",
    x = "Instance",
    y = "Number of Solved Instances",
    fill = "n_mutable_columns"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1), legend.position = "top")  # Rotate x-axis labels for better readability

```

### Computational Times

```{r, fig.width=12, fig.height=5, results="asis"}
for (norm in unique(data$norm)) {
  
  sub_data = data[data$norm == norm,]
  
  sub_data = sub_data %>%
    group_by( sub("^(.+_[0-9]+)_.*", "\\1", full_instance)) %>%
    filter(any(solved == TRUE)) %>%
    ungroup()

  plot = ggplot(sub_data, aes(x = adjusted_time, group = solver, color = solver)) + 
    stat_ecdf(geom = "step") + 
    labs(title = paste0("ECDF of Time for Each Solver using ", norm, " norm"),
         x = "Time",
         y = "ECDF",
         color = "Solver") +
    theme_minimal() +
    theme(legend.position = "bottom") +
    scale_x_continuous(breaks = seq(0, max(sub_data$adjusted_time), by = 300), limits = c(0, time_limit)) +
    scale_y_continuous(breaks = seq(0, 1, by = 0.25)) +
    facet_wrap(~ n_mutable_columns, ncol = 3)  # Facet by mutable_columns, 3 columns
  
  ########## SAVING DATA TO FILE FOR TIKZ ##########
  ecdf_data = data.frame(time = sub_data$adjusted_time)
  
  for (n_mutable_columns_val in unique(sub_data$n_mutable_columns)) {
    
    for (pair_val in unique(paste0(sub_data$method, "_", sub_data$warm_start))) {
      
      parts = strsplit(pair_val, "_")[[1]]
      method_val = parts[1]
      warm_start_val = as.integer(parts[2])
      facet_data = sub_data %>% filter(n_mutable_columns == n_mutable_columns_val & warm_start == warm_start_val & method == method_val)
      
      ecdf_values = ecdf(facet_data$adjusted_time)(sub_data$adjusted_time)
      
      ecdf_data = cbind(ecdf_data, y = ecdf_values)
      colnames(ecdf_data)[ncol(ecdf_data)] = paste0(n_mutable_columns_val, "_", method_val, "_", warm_start_val)
      
    }
  }
  
  ecdf_data <- as.data.frame(ecdf_data)
  ecdf_data <- ecdf_data[order(ecdf_data$time), ]
  ecdf_data = ecdf_data %>% filter(time < time_limit)
  
  indices <- seq(1, length(ecdf_data$time), length.out = 100)
  ecdf_data <- ecdf_data[indices, ]
  
  file_name <- paste0("ecdf_", norm, ".csv")
  write.csv(ecdf_data, file_name, row.names = FALSE)
  ###################################################
  
  print(plot)
   
}
```

## Solution Analysis 


```{r, fig.width=8}
for (norm_val in unique(data$norm)) {
  sub_data = data %>% filter(norm == norm_val)
  
  sub_data = sub_data %>% mutate(l1_norm = ifelse(l1_norm < 1e-5, 1e-5, l1_norm))
  
  sub_data = sub_data %>%
    group_by(full_instance) %>%
    filter(all(solved == TRUE)) %>%
    ungroup()
  
  summarize(sub_data)
  
  plot = ggplot(sub_data, aes(x = l1_norm, y = as.factor(solver), fill = as.factor(solver))) + 
    geom_boxplot() + 
    labs(title = "Over those instances for which all methods computed a feasible point", #paste0("Boxplot of l1-norm of CE when using the objective function: ", norm),
         x = "",
         y = "") +
    scale_y_discrete(labels = c("NLP", "NLP-first", "PADM", "PADM warm start")) +
    scale_x_log10(breaks = scales::log_breaks(base = 10, n = 4)) +
    theme_minimal() +
    theme(legend.position = "none", axis.text.y = element_text(angle = 90, hjust = .5)) # +
    #facet_wrap(~ n_mutable_columns, ncol = 3)
  
  print(plot)
  
  tikz(file = paste0("boxplot_", norm_val, ".tex"), width = 4, height = 3)
  print(plot)
  dev.off()
}
```

## Infeasibility and Fails

```{r}
gurobi_found = data %>%
  filter(method == "NLP", status == "Optimal" | status == "Feasible") %>%
  pull(full_instance)

gurobi_infeasible <- data %>%
  filter(method == "NLP" & status == "Infeasible" & total_time < time_limit) %>%
  pull(full_instance)


gurobi_unknown <- data %>%
  filter(!(full_instance %in% gurobi_found) & !(full_instance %in% gurobi_infeasible)) %>%
  pull(full_instance)

```

### The instance status is Feasible

```{r}

feasible_instances = data %>% 
  filter(method == "PADM") %>% 
  filter(full_instance %in% gurobi_found) %>%
  group_by(solver, status, reason) %>% 
  summarize(
    Count = length(full_instance),
    instances = paste0(paste0(unique(full_instance)[1:5], collapse = ", "), " ...")
  )

feasible_instances %>%
  kable("html", booktabs = TRUE) %>%
  kable_styling(full_width = FALSE) %>%
  collapse_rows(columns = 1, valign = "top")

```

### The instance status is Infeasible

```{r}

infeasible_instances = data %>% 
  filter(method == "PADM") %>% 
  filter(full_instance %in% gurobi_infeasible) %>%
  group_by(solver, status, reason) %>% 
  summarize(
    Count = length(full_instance),
    instances = paste0(paste0(unique(full_instance)[1:5], collapse = ", "), " ...")
  )

infeasible_instances %>%
  kable("html", booktabs = TRUE) %>%
  kable_styling(full_width = FALSE) %>%
  collapse_rows(columns = 1, valign = "top")

```

### The instance status is Unknown


```{r}

unknown_instances = data %>% 
  filter(method == "PADM") %>% 
  filter(full_instance %in% gurobi_unknown) %>%
  group_by(solver, status, reason) %>% 
  summarize(
    Count = length(full_instance), 
    instances = paste0(paste0(unique(full_instance)[1:5], collapse = ", "), " ...")
  )

unknown_instances %>%
  kable("html", booktabs = TRUE) %>%
  kable_styling(full_width = FALSE) %>%
  collapse_rows(columns = 1, valign = "top")

```

```{r}
ws_gap = data %>% 
    filter(method == "PADM", !is.na(warm_start_l1_norm), !is.na(l1_norm)) %>%
    mutate(gap_warm_start = (warm_start_l1_norm - l1_norm) / (1e-10 + warm_start_l1_norm)) %>%
    select(full_instance, n_mutable_columns, warm_start_l1_norm, l1_norm, gap_warm_start)

ws_gap %>% filter(gap_warm_start < 0)

ggplot(ws_gap, aes(x = gap_warm_start)) + 
    stat_ecdf(geom = "step")

x = seq(-1,1,.01)
ecdf_ws_improve = data.frame(
  p = x,
  ecdf = ecdf(ws_gap$gap_warm_start)(x)
)
write.csv(ecdf_ws_improve, file = "ecdf_ws_improve.csv", row.names = FALSE)
```
