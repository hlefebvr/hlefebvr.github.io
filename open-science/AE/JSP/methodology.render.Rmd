---
title: Open methodology for "Adjustable robust optimization with discrete uncertainty" > DisruptionFLP
output: 
  html_document:
    theme: null
    css: /assets/css/design.css
    self_contained: false
    highlight: null
    include:
      in_header: ../../../_includes/head.html
      before_body: 
        - ../../../_includes/header.html
        - ../../../_includes/begin_content.html
        - ../../../_includes/toc.html
        - ../../../_includes/begin_post_content.html
      after_body: 
        - ../../../_includes/handle_page_title.html
        - ../../../_includes/end_post_content.html
        - ../../../_includes/end_content.html
        - ../../../_includes/footer.html
---

<div class="warning">This document is automatically generated after every `git push` action on the public repository `hlefebvr/hlefebvr.github.io` using rmarkdown and Github Actions. This ensures total reproducibility of our data manipulation. Last automatic compilation: `r format(Sys.time(), '%d/%m/%y %H:%M:%S')`.</div>

```{r echo=FALSE}
library(rmarkdown)
library(kableExtra)
library(tidyr)
library(ggplot2)
```

```{r}
data = read.csv("results.jsp.csv", header = FALSE)
colnames(data) = c("tag", "instance", "standard_phase_time_limit", "master_solver", "status", "reason", "has_large_scaled", "n_iterations", "total_time", "master_time", "adversarial_time", "best_bound", "best_obj", "relative_gap", "absolute_gap", "adversarial_unexpected_status",  "with_heuristic", "with_non_optimal_pricing", "n_jobs", "Gamma", "blank")
data = data[, !(names(data) %in% c("tag", "blank"))]
data[data$total_time > 7200,]$total_time = 7200
paged_table(data)
```

```{r}
data$method = paste0(data$master_solver, "_TL", data$standard_phase_time_limit, "_H", data$with_heuristic)
unique(data$method)
data = data[data$method != "STD_TLInf_H1" & data$method != "CG_TL120_H0" & data$method != "CG_TL120_H1",]
```

```{r}
ggplot(data, aes(x = total_time, col = method)) + stat_ecdf(pad = FALSE) + coord_cartesian(xlim = c(0,7200))
```

We export these results in csv to print them in tikz.

```{r}
library(dplyr)

data_with_ecdf = data %>%
  group_by(method) %>%
  arrange(total_time) %>%
  mutate(ecdf_value = ecdf(total_time)(total_time)) %>%
  ungroup()

for (method in unique(data_with_ecdf$method)) {
  output = data_with_ecdf[data_with_ecdf$method == method,]
  output = output[,c("total_time", "ecdf_value")]
  output$log_total_time = log10(output$total_time)
  output = output[output$total_time < 7200,]
  write.csv(output, file = paste0(method, ".csv"), row.names = FALSE)
}
```

```{r}
for (method in unique(data_with_ecdf$method)) {
  filtered_data <- data[data$method == method,] %>%
    filter(total_time == 7200) %>%
    group_by(n_iterations) %>%
    summarize(count = n()) %>%
    ungroup()
  
  # Create a bar plot
  barplot(filtered_data$count, names.arg = filtered_data$n_iterations, xlab = "n_iterations", ylab = "Number of Lines",  main = paste0("Number of unsolved instances, ", method))
}
```

```{r}
# Calculate the summary statistics for instances with total_time < 7200
summary_data_lt_7200 <- data %>%
  filter(total_time < 7200) %>%
  group_by(n_jobs, Gamma, method) %>%
  summarize(
    avg_total_time = mean(total_time, na.rm = TRUE),
    avg_master_time = mean(master_time, na.rm = TRUE),
    avg_adversarial_time = mean(adversarial_time, na.rm = TRUE),
    avg_n_iterations = mean(n_iterations, na.rm = TRUE),
    sum_has_large_scaled = sum(has_large_scaled),
    num_lines = n()
  ) %>%
  ungroup() %>%
  arrange(n_jobs, Gamma, method)

# Calculate the summary statistics for instances with total_time >= 7200
summary_data_ge_7200 <- data %>%
  filter(total_time >= 7200) %>%
  group_by(n_jobs, Gamma, method) %>%
  summarize(
    avg_n_iterations_unsolved = mean(n_iterations, na.rm = TRUE),
    num_lines_unsolved = n()
  ) %>%
  ungroup() %>%
  arrange(n_jobs, Gamma, method)

# Transpose the data for method to be above the table
transposed_data_lt_7200 <- summary_data_lt_7200 %>%
  pivot_wider(names_from = method, values_from = avg_total_time:num_lines)

transposed_data_ge_7200 <- summary_data_ge_7200 %>%
  pivot_wider(names_from = method, values_from = avg_n_iterations_unsolved:num_lines_unsolved) %>%
  select(-n_jobs, -Gamma)

# Create a table using kable
summary_table <- cbind(
  transposed_data_lt_7200,
  transposed_data_ge_7200
) %>%
  kable() %>%
  kable_styling(full_width = FALSE, position = "center")

# Print the table
summary_table
```
