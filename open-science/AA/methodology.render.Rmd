---
title: Open methodology for "A two-stage robust approach for the weighted number of tardy jobs with objective uncertainty"
output: 
  html_document:
    theme: null
    css: /assets/css/design.css
    self_contained: false
    highlight: null
    include:
      in_header: ../../_includes/head.html
      before_body: 
        - ../../_includes/header.html
        - ../../_includes/begin_content.html
        - ../../_includes/toc.html
        - ../../_includes/begin_post_content.html
      after_body: 
        - ../../_includes/end_post_content.html
        - ../../_includes/end_content.html
        - ../../_includes/footer.html
        - ../../_includes/handle_page_title.html
---

<div class="warning">This document is automatically generated after every `git push` action on the public repository `hlefebvr/hlefebvr.github.io` using rmarkdown and Github Actions. This ensures total reproducibility of our data manipulation. Last automatic compilation: `r format(Sys.time(), '%d/%m/%y %H:%M:%S')`.</div>

```{r echo=FALSE}
library(rmarkdown)
```

All results can be found in the CSV file `results.csv` which contains the following rows and columns.

```{r}
all_results = read.csv("results.csv", na.strings = "")
```
```{r echo=FALSE}
paged_table(all_results)
```

Here, columns have the following inerpretation:

- *instance*: instance file name ;
- *problem*: 1 if the row relates to problem $(\mathcal P)$, 2 if it relates to problem $(\widetilde{\mathcal P})$ ;
- *approach*: the approach used for solving the instance,
  - For problem $(\mathcal P)$, possible values are "colgen, kadapt-a, kadapt-b" (in the paper: ColGen1, KAdapt1-a, KAdapt1-b) ;
  - For problem $(\widetilde{\mathcal P})$, possible values are "colgen, colgen-ext, kadapt-a" (in the paper: ColGen2, ColGen3, KAdapt2)
- *n_jobs*: the number of jobs ;
- *gamma*: the value for $\Gamma$ ;
- *k*: when using a $K$-adaptability approach, the value for $K$ ;
- *cpu*: the CPU time needed to sovle the instance (3600 if the time-limit is reached) ;
- *objective*: the best objective value found (i.e., optimal if *cpu* < 3600) ;
- *n_active_col*: when the column generation approach is used, the number of active columns ;
- *quality*: the solution quality,
  - When column generation is used, possible values are "Optimal, TimeLimitFeasible, TimeLimitInfeasible" ;
  - When $K$-adaptability is used, possible values are "Optimal, Time Lim, Mem Lim".
- *gap*: the remaining optimality gap after 1 hour of computation ;
- *rule_for_branching*: when the column generation approach is used, the variable selection rule which were used (possible values: "default, strong_branching", i.e., most infeasible).

## Problem $(\mathcal P)$

We now focus on Problem $(\mathcal P)$. When column generation is used, we only consider the default branching rule (i.e., most infeasible). Indeed, it can be verified that, for this problem, using strong branching is not more efficient than using the most-infeasible rule.

```{r}
problem1 = all_results[all_results$problem == 1,]
colgen1 = problem1[problem1$approach == "colgen" & problem1$rule_for_branching == "default",]
kadapt1_a = problem1[problem1$approach == "kadapt-a",]
kadapt1_b = problem1[problem1$approach == "kadapt-b",]
```

### Estimating $K^*$

```{r}
kadapt1 = merge(kadapt1_a, kadapt1_b, by = c("instance", "n_jobs", "gamma", "k"))
kadapt1 = kadapt1[,c("instance", "n_jobs", "gamma", "k", "objective.x", "objective.y", "cpu.x", "cpu.y")]
colnames(kadapt1) <- c("instance", "n_jobs", "gamma", "k", "obj_kadapt1_a", "obj_kadapt1_b", "cpu_kadapt1_a", "cpu_kadapt1_b")

all1 = merge(colgen1, kadapt1, by = c("instance", "n_jobs", "gamma"), all = TRUE)
all1 = all1[,c("instance", "n_jobs", "gamma", "objective", "k.y", "obj_kadapt1_a", "obj_kadapt1_b", "cpu", "cpu_kadapt1_a", "cpu_kadapt1_b")]
colnames(all1) <- c("instance", "n_jobs", "gamma", "obj_colgen1", "k", "obj_kadapt1_a", "obj_kadapt1_b", "cpu_colgen1", "cpu_kadapt1_a", "cpu_kadapt1_b")
```

```{r}
equals <- function (a, b, tol = 1e-4) {
  return ( abs(a - b) <= tol )
}
```

```{r}
optimal_K1 = all1[
    (
      equals(all1$obj_colgen1, all1$obj_kadapt1_a) | equals(all1$obj_colgen1, all1$obj_kadapt1_b)
    )
    |
    (
      all1$cpu_kadapt1_a >= 3600 | all1$cpu_kadapt1_b >= 3600
    )
  ,]
```

```{r}
optimal_K1 = optimal_K1[order(optimal_K1$instance, optimal_K1$gamma, optimal_K1$k),]
optimal_K1 = optimal_K1[!duplicated(( optimal_K1[,c("instance", "gamma")] )),]
```

```{r}
# Computing average computation time
cpu_times = aggregate(optimal_K1[,c("cpu_kadapt1_a", "cpu_kadapt1_b", "cpu_colgen1")], list(optimal_K1$n_jobs, optimal_K1$gamma), mean)
colnames(cpu_times) <- c("n_jobs", "gamma", "cpu_kadapt1_a", "cpu_kadapt1_b", "cpu_colgen1")

# Sorting by number of jobs and gamma
cpu_times = cpu_times[order(cpu_times$n_jobs, cpu_times$gamma),]

rownames(cpu_times) <- NULL
```

```{r echo=FALSE}
knitr::kable(cpu_times, digits = c(0, 0, 2, 2, 2))
```

```{r} 
optimal_K1$colgen1_is_fastest = optimal_K1$cpu_colgen1 < optimal_K1$cpu_kadapt1_a & optimal_K1$cpu_colgen1 < optimal_K1$cpu_kadapt1_b
optimal_K1$kadapt1_a_is_fastest = optimal_K1$cpu_kadapt1_a < optimal_K1$cpu_colgen1 & optimal_K1$cpu_kadapt1_a < optimal_K1$cpu_kadapt1_b
optimal_K1$kadapt1_b_is_fastest = optimal_K1$cpu_kadapt1_b <= optimal_K1$cpu_colgen1 & optimal_K1$cpu_kadapt1_b <= optimal_K1$cpu_kadapt1_a

# Counting times in which a method is faster than the others
fastest = aggregate(optimal_K1[,c("kadapt1_a_is_fastest", "kadapt1_b_is_fastest", "colgen1_is_fastest")], list(optimal_K1$n_jobs, optimal_K1$gamma), sum)
colnames(fastest) <- c("n_jobs", "gamma", "kadapt1_a_is_fastest", "kadapt1_b_is_fastest", "colgen1_is_fastest")

# Sorting by number of jobs and gamma
fastest = fastest[order(fastest$n_jobs, fastest$gamma),]

rownames(fastest) <- NULL

fastest[,c("kadapt1_a_is_fastest", "kadapt1_b_is_fastest", "colgen1_is_fastest")] = fastest[,c("kadapt1_a_is_fastest", "kadapt1_b_is_fastest", "colgen1_is_fastest")] / rowSums(fastest[,c("kadapt1_a_is_fastest", "kadapt1_b_is_fastest", "colgen1_is_fastest")]) * 100
```


```{r echo=FALSE}
knitr::kable(fastest, digits = c(0, 0, 2, 2, 2))
```

```{r}
optimal_K1$cpu_best = apply(optimal_K1[,c("cpu_colgen1", "cpu_kadapt1_a", "cpu_kadapt1_b")], 1, FUN = min)

optimal_K1$perf_colgen1 = optimal_K1$cpu_colgen1 / optimal_K1$cpu_best
optimal_K1$perf_kadapt1_a = optimal_K1$cpu_kadapt1_a / optimal_K1$cpu_best
optimal_K1$perf_kadapt1_b = optimal_K1$cpu_kadapt1_b / optimal_K1$cpu_best

max_perf = max( max(optimal_K1$perf_colgen1), max(optimal_K1$perf_kadapt1_a), max(optimal_K1$perf_kadapt1_b) )

optimal_K1$perf_colgen1[optimal_K1$cpu_colgen1 >= 3600] = max_perf
optimal_K1$perf_kadapt1_a[optimal_K1$cpu_kadapt1_a >= 3600] = max_perf
optimal_K1$perf_kadapt1_b[optimal_K1$cpu_kadapt1_b >= 3600] = max_perf
```

```{r}
plot_performance_profile <- function(data, xlim = c(0, max_perf), ylim = c(0., 1.), title = "Performance profile") {
  
  perf_profile_colgen1 = ecdf(data[,"perf_colgen1"])
  perf_profile_kadapt1_a = ecdf(data[,"perf_kadapt1_a"])
  perf_profile_kadapt1_b = ecdf(data[,"perf_kadapt1_b"])
  
  plot(perf_profile_colgen1, col = "black", xlim = xlim, ylim = ylim, lty = "solid", cex = 0, main = title)
  lines(perf_profile_kadapt1_a, col = "black", xlim = xlim, ylim = ylim, lty = "dotted", cex = 0)
  lines(perf_profile_kadapt1_b, col = "black", xlim = xlim, ylim = ylim, lty = "dashed", cex = 0)
  
}

xlim = c(0, 2000)

plot_performance_profile(optimal_K1, title = "Over all instances", xlim = xlim)
plot_performance_profile(optimal_K1[optimal_K1$n_jobs == 25,], title = "Over 25-jobs instances", xlim = xlim)
plot_performance_profile(optimal_K1[optimal_K1$gamma <= optimal_K1$n_jobs / 4.,], title = "Over those instances with gamma <= n_jobs / 4", xlim = xlim)
```
